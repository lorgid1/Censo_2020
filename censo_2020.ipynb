{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Censo de poblacion y vivienda 2020"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta libreta contiene un análisis inicial de las columnas del formato del Censo de población y vivienda del año 2020 realizado por el Instituto de Geografia y Estadistica (INEGI) para toda la Republica Méxicana. Corrigue los errores de formato detectados y exporta los diferentes niveles de información que contienen la tabla (Nacional, Estatal, Municipal y Localidad) en un formato adecuado para su importación a bases de datos SQL y su utilización en Sistemas de Información Geográfica."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias y configuraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random as rnd\n",
    "import numpy as np\n",
    "from math import ceil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable definida para imprimir información adicional en la libreta.\n",
    "verbose = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo de datos existe: True\n",
      "El descriptor de base de datos existe: True\n"
     ]
    }
   ],
   "source": [
    "# DATA_DIR es una variable de entorno en mi computadora a la cual se le \n",
    "# asignó el valor de el dicrectorio donde se guardan los datos a procesar.\n",
    "data_dir = os.getenv('DATA_DIR')\n",
    "\n",
    "# La información censal la guardo en una carpeta llamada EventosCensales \n",
    "# dentro del directorio de datos.\n",
    "censales_dir = 'EventosCensales'\n",
    "\n",
    "# Se respetó la estructura de carpetas original que se obtiene al descomprimir \n",
    "# el archivo zip que se obtiene de INEGI. Algunas veces se modifican estos \n",
    "# archivos asi que pueden cambiar. En este caso el zip se descomprimió en una \n",
    "# carpeta llamada iter_00_cpv2020.\n",
    "censo_2020_dir = 'originales/iter_00_cpv2020'\n",
    "\n",
    "# Los datos se encuentran dentro de la carpeta conjunto_de_datos y el descriptor \n",
    "# de cada uno de los campos se encuentra en diccionario_datos.\n",
    "subdir_datos = 'conjunto_de_datos'\n",
    "subdir_descriptor = 'diccionario_datos'\n",
    "\n",
    "# El nombre del archivo donde se encentran los datos es \n",
    "# 'conjunto_de_datos_iter_00CSV20.csv' y descriptor de la base tiene el nombre \n",
    "# 'diccionario_datos_iter_00CSV20.csv'. Los dos vienen en formato csv.\n",
    "archivo_datos = 'conjunto_de_datos_iter_00CSV20.csv'\n",
    "archivo_descriptor = 'diccionario_datos_iter_00CSV20.csv'\n",
    "\n",
    "# Concatenar las rutas de archivos\n",
    "ruta_de_archivo = os.path.join(data_dir, \n",
    "                               censales_dir, \n",
    "                               censo_2020_dir, \n",
    "                               subdir_datos, \n",
    "                               archivo_datos)\n",
    "\n",
    "ruta_de_descriptor = os.path.join(data_dir, \n",
    "                                  censales_dir, \n",
    "                                  censo_2020_dir, \n",
    "                                  subdir_descriptor, \n",
    "                                  archivo_descriptor)\n",
    "\n",
    "if verbose:\n",
    "\n",
    "    print(f'El archivo de datos existe: {os.path.isfile(ruta_de_archivo)}')\n",
    "    print(f'El descriptor de base de datos existe: {os.path.isfile(ruta_de_descriptor)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lorrain\\AppData\\Local\\Temp\\ipykernel_9004\\2739558870.py:2: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raw_censo_2020 = pd.read_csv(ruta_de_archivo)\n"
     ]
    }
   ],
   "source": [
    "# Importar archivo de datos\n",
    "raw_censo_2020 = pd.read_csv(ruta_de_archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar descriptor de datos\n",
    "nuevos_nombres = {\n",
    "    'Núm.':'NUM', \n",
    "    'Indicador':'INDICADOR',\n",
    "    'Descripción':'DESCRIPCION',\n",
    "    'Mnemónico':'NOMCOL',\n",
    "    'Rangos':'RANGOS',\n",
    "    'Longitud':'LONGITUD'\n",
    "}\n",
    "\n",
    "descriptor = pd.read_csv(ruta_de_descriptor, skiprows=4, usecols=list(nuevos_nombres.keys()))\n",
    "descriptor.rename(columns=nuevos_nombres, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis inicial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mayor parte de las columnas se importa como objeto, lo que significa que existen diferentes tipos de datos dentro de cada una de las columnas. Para homogeneizar los datos se tiene que hacer un analisis mas detallado para definir que tipo de dato debe de ser cada una de las columnas y cuales son los valores que no son de este tipo en cada una de ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 195662 entries, 0 to 195661\n",
      "Columns: 286 entries, ENTIDAD to TAMLOC\n",
      "dtypes: int64(6), object(280)\n",
      "memory usage: 426.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Primera descripcion\n",
    "raw_censo_2020.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer registro es un buen acercamiento al tipo de dato que contiene cada una de las columnas. Representa el total nacional, y como tal hay columnas que no aplican. Tal es el caso de las columnas que definen el nombre y clave del Estado, Municipio, y Localidad. No contienen tampoco longitud y latiud, estos datos solo estan presentes en los registros que representan localidades especificas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de columnas 286\n"
     ]
    }
   ],
   "source": [
    "# Diccionario cuyas llaves son el nombre de columna y valores del primer registro \n",
    "# del dataframe.\n",
    "ejemplo_datos = {key : value for key, value in \n",
    "                zip(raw_censo_2020.columns, raw_censo_2020.iloc[0])}\n",
    "\n",
    "if verbose:\n",
    "    print(f'Numero de columnas {len(ejemplo_datos.items())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En general las libretas jupyter no imprimen un texto de mas de ciertas lineas.\n",
    "# para ver todos los registros hay que cambiar los valores dentro de los\n",
    "# corchetes ([0:20]) de la linea comentada para recorrerlos todos. Hay 286 pares \n",
    "# llave: valor en el diccionario.\n",
    "\n",
    "#for item in list(ejemplo_datos.items())[0:20]: print(item)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen tres tipos de columnas que deben estar en formato string. El primer tipo es el que contiene los nombres de los Estados, Municipios y Localidades. El segundo tipo contiene las claves de los diferentes niveles de entidad. Y el tercero contiene las coodenadas geograficas en formato de grados minutos y seguntos. Las columnas que deberian ser texto son las siguientes:\n",
    "\n",
    "['ENTIDAD', 'NOM_ENT', 'MUN', 'NOM_MUN', 'LOC', 'NOM_LOC', 'LONGITUD', 'LATITUD']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resto de las columnas contiene valores numericos. Casi todas tienen el formato de numeros enteros pero 6 que contienen promedios y una que contiene la relacion que existe entre hombres y mujeres de la delimitación geoestadistica. Estos campos contienen decimales por lo que deben de tener el formato Float. Las columnas con valores decimales son:\n",
    "\n",
    "['REL_H_M', 'PROM_HNV', 'GRAPROES', 'GRAPROES_F', 'GRAPROES_M', 'PROM_OCUP', 'PRO_OCUP_C']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resto de las columnas contienen numeros enteros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todas las columnas\n",
    "columnas_censo_2020 = list(raw_censo_2020.columns)\n",
    "\n",
    "# Columnas de texto\n",
    "columnas_string = ['ENTIDAD', 'NOM_ENT', 'MUN', 'NOM_MUN', 'LOC', 'NOM_LOC', \n",
    "                   'LONGITUD', 'LATITUD']\n",
    "# Columnas con valores decimales\n",
    "columnas_decimal = ['REL_H_M', 'PROM_HNV', 'GRAPROES', 'GRAPROES_F', 'GRAPROES_M', \n",
    "                    'PROM_OCUP', 'PRO_OCUP_C']\n",
    "\n",
    "# El resto de las columnas son numeros enteros\n",
    "columnas_entero = [i for i in columnas_censo_2020 \n",
    "                   if i not in columnas_string + columnas_decimal]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen dos valores no numericos en las columnas con formato de numeros enteros y tambien de decimales. Estos valores hacen que el programa represente como objeto todos los registros. Los valores de texto que hay que sustituir son los siguientes:\n",
    "\n",
    "['*', 'N/D']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La columna ALTITUD tiene 32 valores no numericos. En teoria deberia contener valores enteros y va a ser tratado como un caso aparte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tarda un poco en calcularse esta celda\n",
    "valores_string_por_columna = {}\n",
    "for column in columnas_censo_2020:\n",
    "        # Se quitaron las columnas con nombres pero se dejaron las columnas con claves\n",
    "        # alfanumericas\n",
    "        if column not in ['NOM_ENT', 'NOM_MUN', 'NOM_LOC', 'LONGITUD', 'LATITUD']:\n",
    "                valores_no_numericos = tuple(raw_censo_2020[~raw_censo_2020[column]\n",
    "                                                            .astype('string')\n",
    "                                                            .str.strip()\n",
    "                                                            .str.replace('.', '', regex = False)\n",
    "                                                            .str.isnumeric()]\n",
    "                                                            [column].unique())\n",
    "                if valores_no_numericos in valores_string_por_columna.keys():\n",
    "                        valores_string_por_columna[valores_no_numericos] += [column]\n",
    "                \n",
    "                else:\n",
    "                        valores_string_por_columna[valores_no_numericos] = [column]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registros con valores de texto\n",
    "#raw_censo_2020[raw_censo_2020.eq('*').any(1)]\n",
    "#raw_censo_2020[raw_censo_2020.eq('N/D').any(1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas:\n",
      "['ENTIDAD', 'MUN', 'LOC', 'POBTOT', 'VIVTOT', 'TVIVHAB']\n",
      "Valores de texto:\n",
      "()\n",
      "\n",
      "Columnas:\n",
      "['ALTITUD']\n",
      "Valores de texto:\n",
      "('-006', '-001', '-002', '-005', '00-2', '-012', '-007')\n",
      "('-008', '-009', '-003', '-010', '00-1', '00-4', -8.0)\n",
      "(-2.0, -6.0, -5.0, -1.0, -7.0, '-004', '00-3')\n",
      "('-013', -3.0, -18.0, -4.0, -9.0, '00-8', '00-5')\n",
      "(-10.0, -11.0, -12.0, -15.0)\n",
      "\n",
      "Columnas:\n",
      "['POBFEM', 'POBMAS', 'TAMLOC']\n",
      "Valores de texto:\n",
      "('*',)\n",
      "\n",
      "Columnas:\n",
      "['P_0A2', 'P_0A2_F', 'P_0A2_M', 'P_3YMAS', 'P_3YMAS_F', 'P_3YMAS_M', 'P_5YMAS']\n",
      "['P_5YMAS_F', 'P_5YMAS_M', 'P_12YMAS', 'P_12YMAS_F', 'P_12YMAS_M', 'P_15YMAS', 'P_15YMAS_F']\n",
      "['P_15YMAS_M', 'P_18YMAS', 'P_18YMAS_F', 'P_18YMAS_M', 'P_3A5', 'P_3A5_F', 'P_3A5_M']\n",
      "['P_6A11', 'P_6A11_F', 'P_6A11_M', 'P_8A14', 'P_8A14_F', 'P_8A14_M', 'P_12A14']\n",
      "['P_12A14_F', 'P_12A14_M', 'P_15A17', 'P_15A17_F', 'P_15A17_M', 'P_18A24', 'P_18A24_F']\n",
      "['P_18A24_M', 'P_15A49_F', 'P_60YMAS', 'P_60YMAS_F', 'P_60YMAS_M', 'REL_H_M', 'POB0_14']\n",
      "['POB15_64', 'POB65_MAS', 'P_0A4', 'P_0A4_F', 'P_0A4_M', 'P_5A9', 'P_5A9_F']\n",
      "['P_5A9_M', 'P_10A14', 'P_10A14_F', 'P_10A14_M', 'P_15A19', 'P_15A19_F', 'P_15A19_M']\n",
      "['P_20A24', 'P_20A24_F', 'P_20A24_M', 'P_25A29', 'P_25A29_F', 'P_25A29_M', 'P_30A34']\n",
      "['P_30A34_F', 'P_30A34_M', 'P_35A39', 'P_35A39_F', 'P_35A39_M', 'P_40A44', 'P_40A44_F']\n",
      "['P_40A44_M', 'P_45A49', 'P_45A49_F', 'P_45A49_M', 'P_50A54', 'P_50A54_F', 'P_50A54_M']\n",
      "['P_55A59', 'P_55A59_F', 'P_55A59_M', 'P_60A64', 'P_60A64_F', 'P_60A64_M', 'P_65A69']\n",
      "['P_65A69_F', 'P_65A69_M', 'P_70A74', 'P_70A74_F', 'P_70A74_M', 'P_75A79', 'P_75A79_F']\n",
      "['P_75A79_M', 'P_80A84', 'P_80A84_F', 'P_80A84_M', 'P_85YMAS', 'P_85YMAS_F', 'P_85YMAS_M']\n",
      "['PROM_HNV', 'PNACENT', 'PNACENT_F', 'PNACENT_M', 'PNACOE', 'PNACOE_F', 'PNACOE_M']\n",
      "['PRES2015', 'PRES2015_F', 'PRES2015_M', 'PRESOE15', 'PRESOE15_F', 'PRESOE15_M', 'P3YM_HLI']\n",
      "['P3YM_HLI_F', 'P3YM_HLI_M', 'P3HLINHE', 'P3HLINHE_F', 'P3HLINHE_M', 'P3HLI_HE', 'P3HLI_HE_F']\n",
      "['P3HLI_HE_M', 'P5_HLI', 'P5_HLI_NHE', 'P5_HLI_HE', 'PHOG_IND', 'POB_AFRO', 'POB_AFRO_F']\n",
      "['POB_AFRO_M', 'PCON_DISC', 'PCDISC_MOT', 'PCDISC_VIS', 'PCDISC_LENG', 'PCDISC_AUD', 'PCDISC_MOT2']\n",
      "['PCDISC_MEN', 'PCON_LIMI', 'PCLIM_CSB', 'PCLIM_VIS', 'PCLIM_HACO', 'PCLIM_OAUD', 'PCLIM_MOT2']\n",
      "['PCLIM_RE_CO', 'PCLIM_PMEN', 'PSIND_LIM', 'P3A5_NOA', 'P3A5_NOA_F', 'P3A5_NOA_M', 'P6A11_NOA']\n",
      "['P6A11_NOAF', 'P6A11_NOAM', 'P12A14NOA', 'P12A14NOAF', 'P12A14NOAM', 'P15A17A', 'P15A17A_F']\n",
      "['P15A17A_M', 'P18A24A', 'P18A24A_F', 'P18A24A_M', 'P8A14AN', 'P8A14AN_F', 'P8A14AN_M']\n",
      "['P15YM_AN', 'P15YM_AN_F', 'P15YM_AN_M', 'P15YM_SE', 'P15YM_SE_F', 'P15YM_SE_M', 'P15PRI_IN']\n",
      "['P15PRI_INF', 'P15PRI_INM', 'P15PRI_CO', 'P15PRI_COF', 'P15PRI_COM', 'P15SEC_IN', 'P15SEC_INF']\n",
      "['P15SEC_INM', 'P15SEC_CO', 'P15SEC_COF', 'P15SEC_COM', 'P18YM_PB', 'P18YM_PB_F', 'P18YM_PB_M']\n",
      "['GRAPROES', 'GRAPROES_F', 'GRAPROES_M', 'PEA', 'PEA_F', 'PEA_M', 'PE_INAC']\n",
      "['PE_INAC_F', 'PE_INAC_M', 'POCUPADA', 'POCUPADA_F', 'POCUPADA_M', 'PDESOCUP', 'PDESOCUP_F']\n",
      "['PDESOCUP_M', 'PSINDER', 'PDER_SS', 'PDER_IMSS', 'PDER_ISTE', 'PDER_ISTEE', 'PAFIL_PDOM']\n",
      "['PDER_SEGP', 'PDER_IMSSB', 'PAFIL_IPRIV', 'PAFIL_OTRAI', 'P12YM_SOLT', 'P12YM_CASA', 'P12YM_SEPA']\n",
      "['PCATOLICA', 'PRO_CRIEVA', 'POTRAS_REL', 'PSIN_RELIG', 'TOTHOG', 'HOGJEF_F', 'HOGJEF_M']\n",
      "['POBHOG', 'PHOGJEF_F', 'PHOGJEF_M', 'TVIVPAR', 'VIVPAR_HAB', 'VIVPARH_CV', 'TVIVPARHAB']\n",
      "['VIVPAR_DES', 'VIVPAR_UT', 'OCUPVIVPAR', 'PROM_OCUP', 'PRO_OCUP_C', 'VPH_PISODT', 'VPH_PISOTI']\n",
      "['VPH_1DOR', 'VPH_2YMASD', 'VPH_1CUART', 'VPH_2CUART', 'VPH_3YMASC', 'VPH_C_ELEC', 'VPH_S_ELEC']\n",
      "['VPH_AGUADV', 'VPH_AEASP', 'VPH_AGUAFV', 'VPH_TINACO', 'VPH_CISTER', 'VPH_EXCSA', 'VPH_LETR']\n",
      "['VPH_DRENAJ', 'VPH_NODREN', 'VPH_C_SERV', 'VPH_NDEAED', 'VPH_DSADMA', 'VPH_NDACMM', 'VPH_SNBIEN']\n",
      "['VPH_REFRI', 'VPH_LAVAD', 'VPH_HMICRO', 'VPH_AUTOM', 'VPH_MOTO', 'VPH_BICI', 'VPH_RADIO']\n",
      "['VPH_TV', 'VPH_PC', 'VPH_TELEF', 'VPH_CEL', 'VPH_INTER', 'VPH_STVP', 'VPH_SPMVPI']\n",
      "['VPH_CVJ', 'VPH_SINRTV', 'VPH_SINLTC', 'VPH_SINCINT', 'VPH_SINTIC']\n",
      "Valores de texto:\n",
      "('*', 'N/D')\n",
      "\n",
      "Filas en los que aparece el valor N/D: 152\n",
      "Filas en los que aparece el valor *: 87335\n"
     ]
    }
   ],
   "source": [
    "# Resumen valores de texto\n",
    "\n",
    "if verbose:\n",
    "    ND_verdaderos = raw_censo_2020.eq('N/D').any(axis = 1).value_counts()[1]\n",
    "    asterisco_verdaderos = raw_censo_2020.eq('*').any(axis = 1).value_counts()[1]\n",
    "    \n",
    "    elementos_por_linea = 7\n",
    "    for llave, valor in valores_string_por_columna.items():\n",
    "        iteraciones_llaves = len(llave) / elementos_por_linea\n",
    "        iteraciones_valores = len(valor) / elementos_por_linea\n",
    "\n",
    "        if iteraciones_llaves < 1: iteraciones_llaves  = 1\n",
    "        else: iteraciones_llaves = ceil(iteraciones_llaves)\n",
    "\n",
    "        if iteraciones_valores < 1: iteraciones_valores = 1\n",
    "        else: iteraciones_valores = ceil(iteraciones_valores)\n",
    "\n",
    "        \n",
    "        inicial, final = 0, elementos_por_linea\n",
    "        \n",
    "        print('Columnas:')\n",
    "        for columnas_similares in range(0, iteraciones_valores):\n",
    "\n",
    "            print(valor[inicial: final])\n",
    "            inicial += elementos_por_linea\n",
    "            final += elementos_por_linea\n",
    "\n",
    "        print('Valores de texto:')   \n",
    "        inicial, final = 0, elementos_por_linea\n",
    "        for valores_llave in range(0, iteraciones_llaves):\n",
    "\n",
    "            print(llave[inicial:final])\n",
    "            inicial += elementos_por_linea\n",
    "            final += elementos_por_linea\n",
    "        print()\n",
    "    \n",
    "    print(f'Filas en los que aparece el valor N/D: {ND_verdaderos}')\n",
    "    print(f'Filas en los que aparece el valor *: {asterisco_verdaderos}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las columnas LONGITUD y LATITUD tiene la informacion de las coordenadas en formato de grados minutos y segundos. Existen registros sin un valor en estas columnas pero son registros que representan la informacion total nacional, de los estados, municipios y la informacion de localidades de una y dos viviendas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los registros que si contienen información en estas columnas contienen el mismo formato de texto. Una vez que se les quitan los espacios en blanco antes y despues de los textos (.strip), contienen dos o tres digitos seguidos del simbolo de grado (°), seguido de otros dos digitos y el simbolo de minutos ('), seguido de tres digitos mas, un punto (.), tres digitos mas y el simbolo de segundos (\"), seguido de un espacio en blanco y la letra W en la longitud y N para la latitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_censo_2020[raw_censo_2020.LATITUD.isna()].NOM_LOC.unique()\n",
    "#raw_censo_2020[raw_censo_2020.LONGITUD.isna()].NOM_LOC.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    189432\n",
       "NaN       6230\n",
       "Name: LATITUD, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprobar formato de longitud\n",
    "raw_censo_2020.LATITUD\\\n",
    "    .str.strip()\\\n",
    "    .str.contains(r'^\\d{2}°\\d{2}\\'\\d{2}\\.\\d{3}\\\"\\sN$')\\\n",
    "    .value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    189432\n",
       "NaN       6230\n",
       "Name: LONGITUD, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comprobar formato de latitud\n",
    "raw_censo_2020.LONGITUD\\\n",
    "    .str.strip()\\\n",
    "    .str.contains(r'^\\d{2,3}°\\d{2}\\'\\d{2}\\.\\d{3}\\\"\\sW$')\\\n",
    "    .value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#descriptor.columns                   # Columnas del diccionario\n",
    "#list(descriptor.NOMCOL.unique())[:]  # Columnas del iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM:\n",
      "[1]\n",
      "INDICADOR:\n",
      "['Clave de entidad federativa']\n",
      "DESCRIPCION:\n",
      "['Código que identifica a la entidad federativa. El código 00 identifica a los registros con los totales a nivel nacional.']\n",
      "NOMCOL:\n",
      "['ENTIDAD']\n",
      "RANGOS:\n",
      "['00…32']\n",
      "LONGITUD:\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "# Información de columnas del Censo 2020\n",
    "columna_de_interes = 'ENTIDAD'  # Poner columna de interes aqui.\n",
    "info_columna = descriptor[descriptor.NOMCOL.isin([columna_de_interes])]\n",
    "\n",
    "for columna in info_columna.columns:\n",
    "    print(f'{columna}:')\n",
    "    print(info_columna[columna].values)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cambiar el formato a columnas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despues de limpiar los datos en todas las columnas y haber separado la información de coordenadas, quedarán 11 columnas en formato decimal (Float64), 275 en formato de numer entero (Int64), y 8 en formato de texto (string)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columnas de texto"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las columnas con las claves alfanumericas de los estados, municipios y localidades fueron importadas en su mayoria como numeros. Se van a cambiar a formato de numero y se les va a reformatear. para que tengan el numero correcto de caracterers necesario para poder concatenarlas.\n",
    "\n",
    "Entidad es una clave que debe de tener 2 posiciones aunque su valor numerico sea 1. En este caso la clave correcta que debe de tener es '01'. La clave de los municipios esta conformada por 3 posiciones, y la de localidad por 4. Al igual que la clave del estado, si el municipio o la localidad tuvieran asignado el numero 1 para representarlos, las claves correctas deben de ser '001' y '0001' segun sea el caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformatear columnas con claves alfa numericas.\n",
    "for string_column, keylength in zip(['ENTIDAD', 'MUN', 'LOC'], [2, 3, 4]):\n",
    "    raw_censo_2020[string_column] = raw_censo_2020[string_column].astype('string').str.zfill(keylength)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columna in columnas_string:\n",
    "    # Estas ya se cambiaron\n",
    "    if columna not in ['ENTIDAD','MUN', 'LOC']:\n",
    "        raw_censo_2020[columna] = raw_censo_2020[columna].astype('string').str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_censo_2020.iloc[:,0:8].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claves de entidad, municipio y localidad corregidas:\n",
      "\n",
      "ENTIDAD                    12\n",
      "NOM_ENT              Guerrero\n",
      "MUN                       072\n",
      "NOM_MUN     Zapotitlán Tablas\n",
      "LOC                      0117\n",
      "NOM_LOC           Tecualtepec\n",
      "LONGITUD      98°48'13.577\" W\n",
      "LATITUD       17°24'04.473\" N\n",
      "Name: 74081, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Resultado\n",
    "if verbose:\n",
    "    print('Claves de entidad, municipio y localidad corregidas:', end='\\n\\n')\n",
    "    print(raw_censo_2020.iloc[rnd.randint(0,raw_censo_2020.shape[0]),0:8])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columnas numericas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se sustituyeron los valores de texto en las columnas numericas con exepción de ALTITUD con el valor nulo (np.nan). Dependiento del tipo de dato que se definió ademas como numero entero ('Int64'), o como numero decimal ('Float64'). El resultado es 7 columnas decimales y 270 con numeros enteros despues de la columna de altitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sustituir valores de texto por valores nulos (np.nan) y definir el formato de\n",
    "# entero o decimal segun corresponda.\n",
    "\n",
    "for columna in raw_censo_2020.columns:\n",
    "    # Qitar columnas de texto y Altitud\n",
    "    if columna not in columnas_string + ['ALTITUD']:\n",
    "        # Sustituir los valores de texto en columnas numericas por np.nan\n",
    "        raw_censo_2020[columna].replace(to_replace = ['*', 'N/D'], value = np.nan, inplace = True)\n",
    "        # Definir el tipo de columna a Float o a Integer según sea el caso.\n",
    "        if columna in columnas_decimal:\n",
    "            raw_censo_2020[columna] = raw_censo_2020[columna].astype('Float64')\n",
    "        \n",
    "        else:\n",
    "            raw_censo_2020[columna] = raw_censo_2020[columna].astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 195662 entries, 0 to 195661\n",
      "Columns: 277 entries, POBTOT to TAMLOC\n",
      "dtypes: Float64(7), Int64(270)\n",
      "memory usage: 465.2 MB\n"
     ]
    }
   ],
   "source": [
    "# Resultado\n",
    "\n",
    "# Todas las columnas despues del 9 son numericas. El nueve tambien es numerico\n",
    "# pero representa la columna ALTITUD que sera analizada de manera individual\n",
    "# mas adelante. \n",
    "raw_censo_2020.iloc[:, 9:].info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columnas de coordenadas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las columnas LONGITUD Y LATITUD se conservarán tal y como se encuentran pero se procesaran de dos maneras para que existan columnas en el formato que los Sistemas de Información Geografica piden para geolocalizar puntos en el mapa. \n",
    "\n",
    "Los formatos que se aceptan son columnas numericas donde se definen de manera separada los grados, los minutos y los segundos para la longitud y la latiud. Y una sola columna en grados decimales, donde el numero entero representa los grados, y los digitos decimales representan la porcion de minutos y segundos restantes.\n",
    "\n",
    "Antes, los programas GIS necestaban las coordenadas en grados decimales para poder renderizar el mapa. Hoy en dia tambien aceptan la información de grados, minutos y segundos en columnas aparte y lo calculan ellos de manera automatica. Se generarán las columnas para representar las localidades en los dos formatos.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso grados, minutos, y segundos en columnas separadas.\n",
    "\n",
    "# Separar columnas de longitud en grados, minutos, segundos y cardinalidad\n",
    "longitud_separado = raw_censo_2020.LONGITUD.str.split(pat = '[°\\'\\\"]', expand = True, regex = True)\n",
    "latitud_separado = raw_censo_2020.LATITUD.str.split(pat = '[°\\'\\\"]', expand = True, regex = True)\n",
    "\n",
    "# Diccionarios con los nombres de las nuevas columnas\n",
    "columnas_split_lon = {0:'LON_GRAD',1:'LON_MIN',2:'LON_SEG', 3:'LON_CARD'}\n",
    "columnas_split_lat = {0:'LAT_GRAD',1:'LAT_MIN',2:'LAT_SEG',3:'LAT_CARD'}\n",
    "\n",
    "# Renombrar las columnas\n",
    "longitud_separado.rename(columns=columnas_split_lon, inplace=True)\n",
    "latitud_separado.rename(columns=columnas_split_lat, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#longitud_separado.info()     # Tipo de columnas inicial\n",
    "#latitud_separado.info()      # Tipo de columnas fincial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar el formato de las columnas de longitud_separado\n",
    "for columna in longitud_separado.columns:\n",
    "    if columna in ['LON_GRAD', 'LON_MIN']:\n",
    "        longitud_separado[columna] = longitud_separado[columna].astype('Int64')\n",
    "    elif columna in ['LON_SEG']:\n",
    "        longitud_separado[columna] = longitud_separado[columna].astype('Float64')\n",
    "    elif columna in ['LON_CARD']:\n",
    "        longitud_separado[columna] = longitud_separado[columna].astype('string')\\\n",
    "            .str.strip()\n",
    "    else:\n",
    "        print('Te equivocaste en algun nombre')\n",
    "\n",
    "\n",
    "# Cambiar el formato de las columnas de latitud_separado\n",
    "for columna in latitud_separado.columns:\n",
    "    if columna in ['LAT_GRAD', 'LAT_MIN' ]:\n",
    "        latitud_separado[columna] = latitud_separado[columna].astype('Int64')\n",
    "    elif columna in ['LAT_SEG']:\n",
    "        latitud_separado[columna] = latitud_separado[columna].astype('Float64')\n",
    "    elif columna in ['LAT_CARD']:\n",
    "        latitud_separado[columna] = latitud_separado[columna].astype('string')\\\n",
    "            .str.strip()\n",
    "    else:\n",
    "        print('Te equivocaste en algun nombre')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grados decimales se obtienen sumando los grados a los minutos divididos entre 60 y los segundos divididos entre 3600."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso Grados decimales\n",
    "\n",
    "coordenadas_decimales = pd.DataFrame()\n",
    "\n",
    "coordenadas_decimales['LON_DEC'] = longitud_separado.LON_GRAD + \\\n",
    "    (longitud_separado.LON_MIN / 60) + \\\n",
    "        (longitud_separado.LON_SEG / 3600)\n",
    "\n",
    "coordenadas_decimales['LAT_DEC'] = latitud_separado.LAT_GRAD + \\\n",
    "    (latitud_separado.LAT_MIN / 60) + \\\n",
    "        (latitud_separado.LAT_SEG / 3600)\n",
    "\n",
    "coordenadas_decimales['LON_CARD']= longitud_separado.LON_CARD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cardinalidad influye en el signo de las coordenadas geograficas. Si la coordenada longitudinal esta en el lado Oeste (West - W)del meridiano de Greenwich tienen signo negativo. Si las coordenadas geograficas estan al sur del ecuador en la coordenada latitudinal tambien son negativas. Mexico esta arriba del ecuador pero al Oeste del meridiano de Greenwich. Por esta razon se multiplicaran las coordenadas longitudinales por -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a negativo los grados, minutos, y segundos longitudinales al \n",
    "# Oeste del meridiano de Greenwich\n",
    "\n",
    "for columna in ['LON_GRAD', 'LON_MIN', 'LON_SEG']:\n",
    "    longitud_separado.loc[longitud_separado['LON_CARD'] == 'W', columna] = \\\n",
    "        longitud_separado.loc[longitud_separado['LON_CARD'] == 'W', columna] * -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se podia de esta misma manera en los grados y minutos separados porque no hay\n",
    "# localidades Mexicanas al Este del meridiano de Greenwich...\n",
    "coordenadas_decimales['LON_DEC'] = coordenadas_decimales['LON_DEC'] * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitud_separado.drop('LON_CARD', axis = 1, inplace = True)\n",
    "latitud_separado.drop('LAT_CARD', axis = 1, inplace = True)\n",
    "\n",
    "coordenadas_decimales.drop('LON_CARD', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Comprobaciones\n",
    "#(longitud_separado > 0).value_counts() # \n",
    "#(coordenadas_decimales['LON_DEC'] > 0).value_counts()\n",
    "#longitud_separado.columns\n",
    "#latitud_separado.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#longitud_separado.info()     # Tipo de columnas final\n",
    "#latitud_separado.info()      # Tipo de columnas final\n",
    "\n",
    "#raw_censo_2020.columns.get_loc('LONGITUD')   # en indice 6\n",
    "#raw_censo_2020.columns.get_loc('LATITUD')    # en indice 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar columnas corregidas a raw_censo_2020\n",
    "insert_position = raw_censo_2020.columns.get_loc('LATITUD') + 1\n",
    "for columna, valores in pd.concat([longitud_separado, latitud_separado, coordenadas_decimales]\n",
    "                                  , axis = 1).items():\n",
    "\n",
    "    raw_censo_2020.insert(insert_position, columna, valores)\n",
    "    insert_position += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ALTITUD'], dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solo queda la columna ALTITUD como objeto\n",
    "raw_censo_2020.select_dtypes(include=object).columns\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columna de altitud"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ningun registro tiene valores despues del punto decimal y hay 23 registros que no pudieron ser convertidos a valor numerico. Los valores de texto antes detectados son 32. Esto significa que 10 valores de texto tenian el formato necesario para que pandas pudiera interpretarlos como numero.\n",
    "\n",
    "Los datos de la columna seran forzados a enteros, y los valores coercionados a nulos por este proceso seran revisados posteriormente. No son muchos, suponiendo que fueran los inicialmente detectados serian 32 de 189_409. Existen zonas en la superficie terrestre de México que estan abajo del nivel del mar, y es muy posible que sea un problema de formato pero que los valores numericos esten correctos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de valores de texto en columna ALTITUD: 32\n",
      "\n",
      "Valores de texto en la columna ALTITUD:\n",
      "\n",
      "('-006', '-001', '-002', '-005', '00-2', '-012')\n",
      "('-007', '-008', '-009', '-003', '-010', '00-1')\n",
      "('00-4', -8.0, -2.0, -6.0, -5.0, -1.0)\n",
      "(-7.0, '-004', '00-3', '-013', -3.0, -18.0)\n",
      "(-4.0, -9.0, '00-8', '00-5', -10.0, -11.0)\n",
      "(-12.0, -15.0)\n",
      "\n",
      "Remanentes de dividir entre 1 los valores de altitud de las localidades en los registros no nulos convertidos a numero:\n",
      "\n",
      "0.0    189409\n",
      "NaN        23\n",
      "Name: ALTITUD, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Resumen ALTITUD\n",
    "if verbose:\n",
    "    valores_texto_altitud = list(valores_string_por_columna.keys())[1]\n",
    "    total_valores = len(valores_texto_altitud)\n",
    "    valores_a_imprimir = 6\n",
    "    inicial, final = 0, valores_a_imprimir\n",
    "\n",
    "    print(f'Total de valores de texto en columna ALTITUD: {total_valores}', end='\\n\\n')\n",
    "\n",
    "    print('Valores de texto en la columna ALTITUD:', end = '\\n\\n')\n",
    "    for lineas_imprimir in range(0, ceil(total_valores/valores_a_imprimir)):\n",
    "        print(valores_texto_altitud[inicial:final])\n",
    "        inicial += valores_a_imprimir\n",
    "        final += valores_a_imprimir\n",
    "    print()\n",
    "    print('Remanentes de dividir entre 1 los valores de altitud de las localidades',\n",
    "        'en los registros no nulos convertidos a numero:',\n",
    "        end= '\\n\\n')\n",
    "    print( \n",
    "        (pd.to_numeric(raw_censo_2020[raw_censo_2020.LONGITUD.notnull()].ALTITUD, errors='coerce') % 1)\\\n",
    "            .value_counts(dropna=False)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(pd.to_numeric(raw_censo_2020['ALTITUD'], errors= 'coerce') % 1).value_counts()\n",
    "\n",
    "raw_censo_2020['ALTITUD'] = pd.to_numeric(raw_censo_2020['ALTITUD'], errors= 'coerce').astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 195662 entries, 0 to 195661\n",
      "Columns: 294 entries, ENTIDAD to TAMLOC\n",
      "dtypes: Float64(11), Int64(275), string(8)\n",
      "memory usage: 492.2 MB\n"
     ]
    }
   ],
   "source": [
    "# Resultado\n",
    "raw_censo_2020.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corte de los datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La información del censo esta ya en buenas condiciones. Se harán a continuación diferentes cortes de los datos contenidos en el dataframe limpio. La información va ser dividida segun nivel de informacion y software en el que va a ser utilizidad. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corte según niveles de información"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La información va a ser separada por nivel en nacional, estatal, municipal y localidad. Una vez realizada esta división habra que hacer algunas modificaciones a las tablas borrando algunas columnas y cambiando el nombre de otras para ajustar la información a cada nivel.\n",
    "\n",
    "La informacion con la sumatoria de todas las localidades a nivel nacional se identifica con la clave '00' en la columna ENTIDAD porque no representa a ningun estado.\n",
    "\n",
    "Los datos a nivel estatal se encuentran eliminando los datos con la clave '00' en la columna ENTIDAD y en las filas con la clave de municipio (MUN )'000'.\n",
    "\n",
    "Las filas que corresponden a los datos con las sumas municipales se encuentran eliminando los registros con '00' en la columna entidad, y '000' en la columna MUN. Los registros que deben ser incluidos son los que contienen las claves '0000', '9999', y '9998' en la columna LOC.\n",
    "\n",
    "Finalmente, los datos a nivel localidad son los que restan al eliminar la clave '00' en ENTIDAD, '000' en la columna MUN, y '0000', '9999', y '9998' de la columna LOC.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registros a nivel nacional\n",
    "iter_nacional = raw_censo_2020[raw_censo_2020['ENTIDAD'] == '00']\n",
    "\n",
    "# Registros a nivel estatal\n",
    "iter_estatal = raw_censo_2020[(raw_censo_2020['ENTIDAD'] != '00') & \\\n",
    "                              (raw_censo_2020['MUN'] == '000')]\n",
    "\n",
    "# Registros a nivel municipal\n",
    "iter_municipal = raw_censo_2020[(raw_censo_2020['ENTIDAD'] != '00') & \\\n",
    "                                (raw_censo_2020['MUN'] != '000') & \\\n",
    "                                (raw_censo_2020['LOC'].isin(['0000', '9999', '9998']))]\n",
    "\n",
    "# Registros a nivel localidad\n",
    "iter_localidad = raw_censo_2020[(raw_censo_2020['ENTIDAD'] != '00') & \\\n",
    "                                (raw_censo_2020['MUN'] != '000') & \\\n",
    "                                (~raw_censo_2020['LOC'].isin(['0000', '9999', '9998']))]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modificaciones según nivel de información"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen columnas sin información alguna despues de haber separado los registros. Solo los datos a nivel localidad tienen información en todas las columnas una vez que fueron separados.\n",
    "\n",
    "A nivel nacional, estatal y municipal la información de longitud y latitud es inexistente por lo que las columnas que fueron creadas anteriormente tambien estaran vacias. A estas columnas hay que agregar tamaño de localidad a los tres niveles (TAMLOC), ENTIDAD, NOM_ENT, MUN y NOM_MUN a nivel nacional, y MUN y NOM_MUN a nivel estatal.\n",
    "\n",
    "El nombre de las columnas de LOC y NOM_LOC será modificado en los niveles nacional, estatal y muncipal porque las claves que contienen representan las sumatorias de la información en localidades de una sola vivienda (9998), de dos viviendas (9999), y de todas las localidades juntas (0000).\n",
    "\n",
    "A la columna LOC se le asignara 'CV_SUMLOC', que representa 'Clave de Suma de localidades segun numero de vivienda y total'. A la NOM_LOC _se le asignará el nombre DS_SUMLOC y contiene el nombre de las diferentes sumatorias que se realzan en esas filas.\n",
    "\n",
    "A nivel localidad y municipal se concatenara una clave que represente a cada entidad de manera única. Para los municipios esto se logra concatenando la columnas columnas con la clave del estado (ENTIDAD) y la del municipio (MUN). Para las localidades se tiene que agregar la columna con la clave de la localidad (LOC). El nombre de las columnas será CVE_GEO_M y CVE_GEO_L para la tabla de municipios y localidades respectivamente.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis iter_nacional\n",
    "remover_columnas_nal = ['LONGITUD', 'LATITUD', 'LON_GRAD', 'LON_MIN', 'LON_SEG', \n",
    "                        'LAT_GRAD', 'LAT_MIN', 'LAT_SEG', 'LON_DEC', 'LAT_DEC', \n",
    "                        'ALTITUD', 'TAMLOC', 'ENTIDAD', 'MUN', 'NOM_MUN', 'NOM_ENT']\n",
    "\n",
    "#iter_nacional.isnull().all().value_counts()                # 12 columnas no tienen ningun valor\n",
    "#iter_nacional.isnull().all()[iter_nacional.isnull().all() == True].index  \n",
    "                                                            # Columnas que no tienen registros\n",
    "\n",
    "#iter_nacional[['ENTIDAD', 'MUN', 'LOC']].value_counts()    # Todos los valores son iguales en las\n",
    "                                                            # columnas ENTIDAD y MUN, la columna\n",
    "                                                            # LOC contiene tres valores\n",
    "\n",
    "#iter_nacional.NOM_LOC.value_counts()                       # Las clave de LOC representan la suma\n",
    "                                                            # de los datos segun el numero de\n",
    "                                                            # viviendas que hay en la localidad.                                                          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lorrain\\AppData\\Local\\Temp\\ipykernel_9004\\2825823151.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iter_nacional.drop(columns= remover_columnas_nal, axis=1, inplace=True)\n",
      "C:\\Users\\Lorrain\\AppData\\Local\\Temp\\ipykernel_9004\\2825823151.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iter_nacional.rename(columns={'LOC':'CV_SUMLOC', 'NOM_LOC':'DS_SUMLOC'}, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "# Transformaciones iter_nacional\n",
    "\n",
    "# Remover columnas\n",
    "iter_nacional.drop(columns= remover_columnas_nal, axis=1, inplace=True)\n",
    "\n",
    "# Renombrar columnas\n",
    "iter_nacional.rename(columns={'LOC':'CV_SUMLOC', 'NOM_LOC':'DS_SUMLOC'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados y comprobaciones iter_nacional\n",
    "\n",
    "# iter_nacional.columns   # Columnas fueron removidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis iter_estatal\n",
    "\n",
    "remover_columnas_ent = ['LONGITUD', 'LATITUD', 'LON_GRAD', 'LON_MIN', 'LON_SEG', \n",
    "                        'LAT_GRAD', 'LAT_MIN', 'LAT_SEG', 'LON_DEC', 'LAT_DEC', \n",
    "                        'ALTITUD', 'TAMLOC', 'MUN', 'NOM_MUN']\n",
    "\n",
    "#iter_estatal.isnull().all().value_counts()             # 12 columnas no tienen ningun valor\n",
    "#iter_estatal.isnull().all()[iter_nacional.isnull().all() == True].index  \n",
    "                                                        # Columnas que no tienen registros\n",
    "\n",
    "#iter_estatal['ENTIDAD'].value_counts().index           # ENTIDAD contiene valores del 01 - 32 que\n",
    "                                                        # representa a cada uno de los estados\n",
    "\n",
    "#iter_estatal[['MUN', 'LOC']].value_counts()            # Todos los valores en MUN son iguales\n",
    "                                                        # y no representan nada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lorrain\\AppData\\Local\\Temp\\ipykernel_9004\\3468801214.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iter_estatal.drop(columns=remover_columnas_ent, axis=1, inplace=True)\n",
      "C:\\Users\\Lorrain\\AppData\\Local\\Temp\\ipykernel_9004\\3468801214.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iter_estatal.rename(columns={'LOC':'CV_SUMLOC', 'NOM_LOC':'DS_SUMLOC'}, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "# Transformaciones iter_estatal\n",
    "\n",
    "# Remover columnas\n",
    "iter_estatal.drop(columns=remover_columnas_ent, axis=1, inplace=True)\n",
    "\n",
    "# Renombrar columnas\n",
    "iter_estatal.rename(columns={'LOC':'CV_SUMLOC', 'NOM_LOC':'DS_SUMLOC'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados y comprobaciones iter_estatal\n",
    "\n",
    "#iter_estatal.columns     # Columnas fueron removidas y se insertó CVE_GEO_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis iter_municipal\n",
    "\n",
    "remover_columnas_mun = ['LONGITUD', 'LATITUD', 'LON_GRAD', 'LON_MIN', 'LON_SEG', \n",
    "                        'LAT_GRAD', 'LAT_MIN', 'LAT_SEG', 'LON_DEC', 'LAT_DEC', \n",
    "                        'ALTITUD', 'TAMLOC']\n",
    "\n",
    "#iter_municipal.isnull().all().value_counts()               # 12 columnas no tienen ningun valor\n",
    "#iter_municipal.isnull().all()[iter_nacional.isnull().all() == True].index  \n",
    "                                                            # Columnas que no tienen registros\n",
    "\n",
    "#iter_municipal['ENTIDAD'].value_counts().index.min()       # Valor minimo de 01\n",
    "#iter_municipal['ENTIDAD'].value_counts().index.max()       # Valor maximo de 32\n",
    "\n",
    "#iter_municipal['MUN'].value_counts().index.min()           # Valor minimo es de 001\n",
    "#iter_municipal['MUN'].value_counts().index.max()           # Valor maximo de 570 (representa el \n",
    "                                                            # numero maximo de municipios en un\n",
    "                                                            # estado)\n",
    "\n",
    "\n",
    "#iter_municipal[iter_municipal.LOC.isin(['0000','9999', '9998'])].NOM_LOC.value_counts()\n",
    "                                                            # Las claves '9999' y '9998' no \n",
    "                                                            # representan localidades especificas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lorrain\\AppData\\Local\\Temp\\ipykernel_9004\\4206078098.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iter_municipal.drop(columns=remover_columnas_mun, axis=1, inplace=True)\n",
      "C:\\Users\\Lorrain\\AppData\\Local\\Temp\\ipykernel_9004\\4206078098.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iter_municipal.rename(columns={'LOC':'CV_SUMLOC', 'NOM_LOC':'DS_SUMLOC'}, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "# Transformaciones iter_municipal\n",
    "\n",
    "# Crear serie clave geoestadistica concatenada de ENTIDAD, MUN\n",
    "clave_geo_municipal = iter_municipal['ENTIDAD'] + iter_municipal['MUN']\n",
    "\n",
    "# Agregar serie como columna al principio del data frame\n",
    "iter_municipal.insert(loc = 0, column = 'CVE_GEO_M', value= clave_geo_municipal)\n",
    "\n",
    "# Remover columnas\n",
    "iter_municipal.drop(columns=remover_columnas_mun, axis=1, inplace=True)\n",
    "\n",
    "# Renombrar columnas\n",
    "iter_municipal.rename(columns={'LOC':'CV_SUMLOC', 'NOM_LOC':'DS_SUMLOC'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados y comprobaciones iter_municipal\n",
    "\n",
    "#iter_municipal.columns                          # Las columnas fueron removidas\n",
    "#iter_municipal.CVE_SUMLOC.value_counts()         # Solo la clave '0000' esta presente\n",
    "                                                 # en todos los municipios\n",
    "\n",
    "#iter_municipal.loc[iter_municipal['CVE_SUMLOC'] == '0000'].CVE_GEO_M.is_unique\n",
    "                                                 # Si se separa por claves CVE_SUMLOC\n",
    "                                                 # solo tiene valores únicos\n",
    "\n",
    "#iter_municipal.loc[iter_municipal['CVE_SUMLOC'] == '9998'].CVE_GEO_M.is_unique\n",
    "                                                 # Valores únicos\n",
    "\n",
    "#iter_municipal.loc[iter_municipal['CVE_SUMLOC'] == '9999'].CVE_GEO_M.is_unique\n",
    "                                                 # Valores únicos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis iter_localidad\n",
    "\n",
    "#iter_localidad.isnull().all().value_counts()               # No hay columnas sin valor\n",
    "\n",
    "#iter_localidad['LOC'].value_counts().index.min()           # Valor minimo de 0001\n",
    "#iter_localidad['LOC'].value_counts().index.max()           # Valor maximo de 6454\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformaciones iter_localidad\n",
    "\n",
    "# Crear serie clave geoestadistica concatenada de ENTIDAD, MUN, y LOC\n",
    "clave_geo_localidad = iter_localidad['ENTIDAD'] + iter_localidad['MUN'] + iter_localidad['LOC']\n",
    "\n",
    "# Agregar serie como columna al principio del data frame\n",
    "iter_localidad.insert(loc = 0, column = 'CVE_GEO_L', value= clave_geo_localidad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados y comprobaciones iter_localidad\n",
    "#iter_localidad.columns                  # Se insertó CVE_GEO_L\n",
    "#iter_localidad.CVE_GEO_L.is_unique      # Todos los valores de la columna son unicos\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cortes para SQL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "Para almacenar los datos en bases de datos SQL, la información tiene que dividirse de manera coerente y eficiente en tablas relacionables. Existen ciertas reglas de nomenclatura, las tablas y las columnas no pueden empezar con numeros, y en general los programas usan los sufijos para relacionar tablas. Tomando en cuenta la experiencia de como se usan estos datos, la información se dividira de la siguiente manera para SQL:\n",
    "\n",
    "* Tabla con la información censal a nivel nacional\n",
    "* Tabla con informacion de claves de division politica y nombres para:\n",
    "    * estados\n",
    "    * municipios\n",
    "    * localidades\n",
    "* Tabla con información del censo 2020 para:\n",
    "    * estados\n",
    "    * municipios\n",
    "    * localidades\n",
    "* Tabla con información de coordenadas para las localidades\n",
    "\n",
    "Las tablas de localidades se relacionaran con CVE_GEO_L, las de municipios con CVE_GEO_M y las de estados con la columna ENTIDAD. Existen las columnas necesarias dentro de la tabla de claves para relacionar los diferentes niveles exepto nacional. El poder computacional de las bases de datos SQL es bastante grande, especialmente porque su interfaz grafica es minima, por lo que no creo necesario hacer subdivisiones a la información del censo 2020 a nivel localidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_clave_estados = iter_estatal['ENTIDAD']\n",
    "col_clave_municipios = iter_municipal['CVE_GEO_M']\n",
    "col_clave_localidades = iter_localidad['CVE_GEO_L']\n",
    "\n",
    "tablas_sql = {\n",
    "\n",
    "'ent_iter_2020' : iter_estatal.iloc[:,0:2].drop_duplicates(),\n",
    "'ent_iter_censo_2020' : pd.concat([col_clave_estados, iter_estatal.iloc[:,2:]], axis=1),\n",
    "\n",
    "'mun_iter_2020': iter_municipal.iloc[:, 0:5].drop_duplicates(),\n",
    "'mun_censo_iter_2020' : pd.concat([col_clave_municipios, iter_municipal.iloc[:,5:]], axis = 1),\n",
    "\n",
    "'loc_iter_2020' : iter_localidad.iloc[:,0:7],\n",
    "'loc_id_geo_iter_2020 ' : pd.concat([col_clave_localidades, iter_localidad.iloc[:,7:18]], axis = 1),\n",
    "'loc_censo_iter__2020' : pd.concat([col_clave_localidades, iter_localidad.iloc[:,18:]], axis = 1)\n",
    "\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cortes para SIG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los sistemas de información geografica necesitan sus tablas con ciertas caracteristicas. Los titulos de las columnas no deben de tener mas de 9 caracteres y deben ser de un solo tipo de valor (numero entero, decimal, string, o fecha) o serán consideradas como texto. Todas las columnas cumplen con estos dos requisitos.\n",
    "\n",
    "\n",
    "Las tablas tampoco deben de tener multiples filas para el mismo elemento que se va a representar. Esto significa que las tablas a nivel nacional, estatal y municipal con la suma de todas las localidades, las localidades de una sola vivienda, y las localidades de dos viviendas tienen que ser separadas en varias tablas. De no ser asi, al relacionarlas con su reresentación geografica, el programa tomará el primer registro e ignorará el resto.\n",
    "\n",
    "\n",
    "Los datos a nivel entidad y municipal se dividiran en las siguientes tablas para facilitar su uso en Sistemas de Información Geográfica:\n",
    "\n",
    "    \n",
    "* Tabla de estados y de municipios para:\n",
    "\n",
    "\n",
    "    * La suma de todas las localidades\n",
    "    * La suma de localidades con 1 vivienda\n",
    "    * La suma de localidades con 2 viviendas\n",
    "\n",
    "Para ser utilizadas en SIG, las tablas tienen que ser importadas y unidas a poligonos, lineas o puntos que representen su contenido gráficamente en formato vectorial. Los archivos mas utilizados son los que proporciona Inegi. Estos ya tienen en su tabla interna el nombre y las claves de los municipios por lo que se exportarán sin los nombres y solo con la clave necesaria para que pudenan ser unidos a los mapas que se proporcionan a travez de las columnas ENTIDAD y CVE_GEO_M.\n",
    "\n",
    "Nacional no será separado porque al solo ser un poligono no se usará para el procesamiento y analisis espacial. Esto sería diferente si la base de datos tuviera información de dos o mas paises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir estados por tipo de suma de localidades\n",
    "\n",
    "tablas_estados = {\n",
    "    '2020_iter_ent_tot' : iter_estatal.loc[iter_estatal['CV_SUMLOC'] == '0000'],\n",
    "    '2020_iter_ent_l1v' : iter_estatal.loc[iter_estatal['CV_SUMLOC'] == '9998'],\n",
    "    '2020_iter_ent_l2v' : iter_estatal.loc[iter_estatal['CV_SUMLOC'] == '9999'],\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iter_estatal['CV_SUMLOC'].value_counts()      # Todas las claves tienen la misma cantidad de registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir municipios por tipo de suma de localidades\n",
    "tablas_municipios = {\n",
    "    '2020_iter_mun_tot' : iter_municipal.loc[iter_municipal['CV_SUMLOC'] == '0000'],\n",
    "    '2020_iter_mun_l1v' : iter_municipal.loc[iter_municipal['CV_SUMLOC'] == '9998'],\n",
    "    '2020_iter_mun_l2v' : iter_municipal.loc[iter_municipal['CV_SUMLOC'] == '9999']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iter_municipal['CV_SUMLOC'].value_counts()[0]\n",
    "#iter_municipal['CV_SUMLOC'].value_counts()[0] == len(municipios)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las localidades no solo se representan como puntos, los marcos geoestadisticos que proporciona INEGI tienen archivos que representan muchas de las localidades en formato de poligono. Las que todavia no tienen poligono son representadas en otro archivo por puntos. Las tablas que seran exportadas son:\n",
    "* Tabla solamente con la informacion de claves, nombres y geolocalización\n",
    "* Tabla con toda la información censal\n",
    "* Tablas con la información censal dividia por temas de INEGI\n",
    "    * Población\n",
    "    * Estructura por Edad y Sexo\n",
    "    * Fecundidad\n",
    "    * Migración\n",
    "    * Etnicidad\n",
    "    * Discapacidad\n",
    "    * Educación\n",
    "    * Características económicas\n",
    "    * Servicios de salud\n",
    "    * Situación conyugal\n",
    "    * Religión\n",
    "    * Hogares censales\n",
    "    * Vivienda\n",
    "\n",
    "Son muchas las maneras en que se puede dividir la información, y muchas veces hay que tomar uno o varios campos de uno o varios temas. Para eso esta la tabla con toda la información censal. Muchas veces solo se necesita un tema especifico, para estas veces, y por lo pesado de los archvios cuando se le agrega una representacion grafica, fueron separados por tema. Esta es solo una propuesa de división basada en mi experiencia. Hay otras formas según diferentes necesidades de análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columnas_tablas_loc = {\n",
    "    '2020_iter_localidades' : list(raw_censo_2020.columns[0:6]) + ['LON_DEC', 'LAT_DEC'],\n",
    "                                                                            # Desde ENTIDAD a NOM_LOC\n",
    "                                                                            # + LON_DEC y LAT_DEC\n",
    "    '2020_iter_loc_id_geo' : list(raw_censo_2020.columns[6:17]),            # Desde LONGITUD hasta ALTITUD\n",
    "    '2020_iter_loc_poblacion' : list(raw_censo_2020.columns[17:64]),        # Desde POBTOT hasta POB65_MAS\n",
    "    '2020_iter_loc_estructura_pob' : list(raw_censo_2020.columns[64:118]),  # Desde P_0A4 hasta P_85YMAS_M\n",
    "    '2020_iter_loc_fecundiad' :  list(raw_censo_2020.columns[118:119]),     # Solo PROM_HNV\n",
    "    '2020_iter_loc_migracion' : list(raw_censo_2020.columns[119:131]),      # Desde PNACENT hasta PRESOE15_M\n",
    "    '2020_iter_loc_etnicidad' : list(raw_censo_2020.columns[131:147]),      # Desde P3YM_HLI hasta POB_AFRO_M\n",
    "    '2020_iter_loc_discapacidad' : list(raw_censo_2020.columns[147:163]),   # Desde PCON_DISC hasta PSIND_LIM\n",
    "    '2020_iter_loc_educacion' : list(raw_censo_2020.columns[163:205]),      # Desde P3A5_NOA hasta GRAPROES_M\n",
    "    '2020_iter_loc_economia' : list(raw_censo_2020.columns[205:217]),       # Desde PEA hasta PDESOCUP_M\n",
    "    '2020_iter_loc_salud' : list(raw_censo_2020.columns[217:227]),          # Desde PSINDER hasta PAFIL_OTRAI\n",
    "    '2020_iter_loc_conyugal' : list(raw_censo_2020.columns[227:230]),       # Desde P12YM_SOLT hasta P12YM_SEPA\n",
    "    '2020_iter_loc_religion' : list(raw_censo_2020.columns[230:234]),       # Desde PCATOLICA hasta PSIN_RELIG\n",
    "    '2020_iter_loc_hogares' : list(raw_censo_2020.columns[234:240]),        # Desde TOTHOG hasta PHOGJEF_M\n",
    "    '2020_iter_loc_vivienda' : list(raw_censo_2020.columns[240:] )          # Desde VIVTOT hasta TAMLOC\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario de tablas a nivel localidad\n",
    "tablas_localidad = {}\n",
    "\n",
    "# Censo completo por localidad\n",
    "tablas_localidad['2020_iter_loc_censo'] = iter_localidad\n",
    "\n",
    "# Iter a nivel localidad por temas de INEGI segun las columnas previamente definidas\n",
    "for nombre_tabla, lista_columnas in columnas_tablas_loc.items():\n",
    "    \n",
    "    columnas_tabla = ['CVE_GEO_L'] + lista_columnas\n",
    "    tablas_localidad[nombre_tabla] =  iter_localidad.loc[:, columnas_tabla]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tablas_localidad['2020_iter_salud_loc']\n",
    "#tablas_localidad['2020_iter_id_geo_loc']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregar indicadores creados al descriptor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los indicadores creados serán agragados al descriptor de datos original y despues serán exportados con los diferentes cortes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario de indicadores generados\n",
    "indicadores_agregados = {\n",
    "\n",
    "    'LON_GRAD' : {\n",
    "        'indicador' : 'Grados de longitud',\n",
    "        'descripcion' : 'Grados de la longitud geográfica.',\n",
    "        'rangos' : '-180...180',\n",
    "        'longitud' : 3\n",
    "    },\n",
    "\n",
    "    'LON_MIN' : {\n",
    "        'indicador' : 'Minutos de longitud',\n",
    "        'descripcion' : 'Minutos de la longitud geográfica.',\n",
    "        'rangos' : '-59...59',\n",
    "        'longitud' : 2\n",
    "    },\n",
    "\n",
    "    'LON_SEG' : {\n",
    "        'indicador' : 'Segundos de longitud',\n",
    "        'descripcion' : 'Segundos de la longitud geográfica.',\n",
    "        'rangos' : '-59.999...59.999',\n",
    "        'longitud' : 9\n",
    "    },\n",
    "\n",
    "    'LAT_GRAD' : {\n",
    "        'indicador' : 'Grados de latitud',\n",
    "        'descripcion' : 'Grados de la latitud geográfica.',\n",
    "        'rangos' : '-90...90',\n",
    "        'longitud' : 2\n",
    "    },\n",
    "\n",
    "    'LAT_MIN' : {\n",
    "        'indicador' : 'Minutos de latitud',\n",
    "        'descripcion' : 'Minutos de la latitud geográfica.',\n",
    "        'rangos' : '-59...59',\n",
    "        'longitud' : 2\n",
    "    },\n",
    "\n",
    "    'LAT_SEG' : {\n",
    "        'indicador' : 'Segundos de latitud',\n",
    "        'descripcion' : 'Segundos de la latitud geográfica.',\n",
    "        'rangos' :  '-59.999...59.999',\n",
    "        'longitud' :  9\n",
    "    },\n",
    "\n",
    "    'LON_DEC' : {\n",
    "        'indicador' : 'Longitud grados decimales',\n",
    "        'descripcion' : 'Longitud en grados decimales.',\n",
    "        'rangos' : '-180...180',\n",
    "        'longitud' : 9\n",
    "    },\n",
    "\n",
    "    'LAT_DEC' : {\n",
    "        'indicador' : 'Latitud grados decimales',\n",
    "        'descripcion' : 'Latitud en grados decimales.',\n",
    "        'rangos' : '-90...90',\n",
    "        'longitud' : 9\n",
    "    },\n",
    "\n",
    "    'CV_SUMLOC' : {\n",
    "        'indicador' : 'Clave de Suma de localidades según número de vivienda y total',\n",
    "        'descripcion' : 'Clave que representa la suma del total de viviendas (0000) y el total de las localidades de una (9998) y dos viviendas (9999).',\n",
    "        'rangos' : '0000,9998...9999',\n",
    "        'longitud' : 4\n",
    "    },\n",
    "\n",
    "    'DS_SUMLOC' : {\n",
    "        'indicador' : 'Descripcion de la suma de localidades según número de vivienda y total',\n",
    "        'descripcion' : 'DescripcionSuma de las localidades de una (9998) y dos viviendas (9999) y del total de viviendas (0000).',\n",
    "        'rangos' : 'Alfanumérico',\n",
    "        'longitud' : 50\n",
    "    },\n",
    "    \n",
    "    'GVE_GEO_L' : {\n",
    "        'indicador' : 'Clave geoestadística de la localidad',\n",
    "        'descripcion' : 'Clave geoestadística de la localidad concatenada con las claves de estado, municipio y loalidad.',\n",
    "        'rangos' : 'Alfanumérico',\n",
    "        'longitud'  : 9\n",
    "    },\n",
    "\n",
    "    'CVE_GEO_M' : {\n",
    "        'indicador' : 'Clave geoestadística del municipio',\n",
    "        'descripcion' : 'Clave geoestadística del municipio concatenada con las claves de estado y municipio.',\n",
    "        'rangos' : 'Alfanumérico',\n",
    "        'longitud' : 5\n",
    "    }\n",
    "\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar indicadores a descriptor\n",
    "ultimo_indice = 0\n",
    "\n",
    "for indicador, dic_columna in indicadores_agregados.items():\n",
    "    ultimo_indice = ultimo_indice + 1\n",
    "    a_unir = [ultimo_indice, \n",
    "              dic_columna['indicador'], \n",
    "              dic_columna['descripcion'],\n",
    "              indicador,\n",
    "              dic_columna['rangos'],\n",
    "              dic_columna['longitud']]\n",
    "    descriptor.loc[len(descriptor.index)] = a_unir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultado\n",
    "\n",
    "#descriptor.iloc[-12:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportar las tablas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se exportaran las tablas en formatos y con las modificaciones convenientes para diferentes fines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir ruta para exportar archivos\n",
    "os.listdir(os.path.join(data_dir, censales_dir))\n",
    "\n",
    "# Directorio donde se van a exportar las tablas\n",
    "directorio_exportar = '2020_censo'\n",
    "\n",
    "# Ruta donde se van a exportar las tablas\n",
    "ruta_exportar = os.path.join(data_dir, censales_dir, directorio_exportar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio ya existe.\n"
     ]
    }
   ],
   "source": [
    "# Revisar si existe el directorio\n",
    "\n",
    "if not os.path.isdir(ruta_exportar):\n",
    "    os.mkdir(ruta_exportar)\n",
    "\n",
    "else:\n",
    "    print('Directorio ya existe.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportar tablas para SIG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las tablas que son importadas a Sistemas de Información Geográfica tienen ciertas caracteristicas. Los titulos de las columnas no deben de tener mas de 10 caracteres y no pueden empezar con numeros. Ninguno de los titulos de las columnas esta fuera de esta norma. \n",
    "\n",
    "Otro requerimiento importante es que los datos en cada una de las columnas sean del mismo tipo. Esto se cumple al momento pero a la hora de exportarse los valores nulos seran convertidos a texto vació. Para evitar que las columnas sean convertidas a texto por esta razón se asignara el valor numerico -9999 a todos los registros con valor nulo.\n",
    "\n",
    "El SIG para el cual serán exportados es QGIS. Este SIG necesita de un archivo con el mismo nombre del csv pero con la terminacion .csvt en donde se defina el tipo de datos en cada uno de las columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nombre, tabla in tablas_estados.items():\n",
    "    tablas_estados[nombre] = tablas_estados[nombre].fillna(-9999)\n",
    "\n",
    "for nombre, tabla in tablas_municipios.items():\n",
    "    tablas_municipios[nombre] = tablas_municipios[nombre].fillna(-9999)\n",
    "\n",
    "for nombre, tabla in tablas_localidad.items():\n",
    "    tablas_localidad[nombre] = tablas_localidad[nombre].fillna(-9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_csvt(nombre:str, tabla:pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Función que extrae y regresa el tipo de columna de un dataframe.\n",
    "\n",
    "      :param nombre: Nombre del dataframe entrante.\n",
    "      :param tabla: Dataframe del cual se va a extraer el tipo de colummna.\n",
    "\n",
    "      :return: Regresa un dataframe de columnas sin nombre con un valor de\n",
    "         tipo de columna.\n",
    "    '''\n",
    "    lista_tipos = []\n",
    "\n",
    "    for col_type in tabla.dtypes:\n",
    "        if col_type == 'string': lista_tipos.append('String')\n",
    "        elif col_type == 'Int64': lista_tipos.append('Integer')\n",
    "        elif col_type == 'Float64': lista_tipos.append('Real')\n",
    "        else:  print(f'Valor no contemplado: {col_type} en {nombre}')\n",
    "        serie_tipos = pd.Series(lista_tipos)\n",
    "        data_frame_tipos = pd.DataFrame(serie_tipos).T\n",
    "\n",
    "\n",
    "    return(data_frame_tipos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportar_csv_con_csvt(nombre:str, \n",
    "                          ruta_exportar:str, \n",
    "                          tabla_csv:pd.DataFrame,\n",
    "                          verbose = False):\n",
    "    '''\n",
    "    Función que exporta un dataframe a csv y un archivo csvt.\n",
    "\n",
    "      :param nombre: Nombre del dataframe entrante.\n",
    "      :param ruta_exportar: Ruta donde se va a guardar el archivo.\n",
    "      :param tabla: Dataframe del cual se va a extraer el tipo de colummna.\n",
    "\n",
    "      :return: Nada, guarda dos archivos en la pc.\n",
    "    '''\n",
    "    csv_file = nombre + '.csv'\n",
    "    csvt_file = nombre + '.csvt'\n",
    "\n",
    "    tabla_csvt = dataframe_csvt(nombre, tabla_csv)\n",
    "\n",
    "    ruta_csv = os.path.join(ruta_exportar, csv_file)\n",
    "\n",
    "    if verbose:\n",
    "      if os.path.isfile(ruta_csv): print(f'Archivo {csv_file} ya existe... sobreescribiendo')\n",
    "      else: print(f'Creando archivo {csv_file}')\n",
    "\n",
    "    tabla_csv.to_csv(ruta_csv, \n",
    "                     index = False,\n",
    "                     encoding='utf-8')\n",
    "    \n",
    "    if verbose:\n",
    "      if os.path.isfile(ruta_csvt): print(f'Archivo {csvt_file} ya existe... sobreescribiendo')\n",
    "      else: print(f'Creando archivo {csvt_file}')\n",
    "\n",
    "    tabla_csvt.to_csv(os.path.join(ruta_exportar, csvt_file),\n",
    "                                           index = False,\n",
    "                                           index_label = False,\n",
    "                                           quoting = 1, # esto significa csv.QUOTEALL\n",
    "                                           mode = 'w',\n",
    "                                           header= False,\n",
    "                                           encoding='utf-8')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta para guardar tablas iter de estados\n",
    "ruta_exportar_estados = os.path.join(ruta_exportar, 'ent_iter')\n",
    "# Revisar si existe directorio de estados sino crearlo\n",
    "if not os.path.isdir(ruta_exportar_estados): os.mkdir(ruta_exportar_estados)\n",
    "else: print('Directorio estados ya existe.')\n",
    "# Exportar tablas csv y csvt de estados\n",
    "for nombre, tabla in tablas_estados.items():\n",
    "    exportar_csv_con_csvt(nombre, ruta_exportar_estados, tabla)\n",
    "\n",
    "# Crear ruta para guardar tablas iter de municipios\n",
    "ruta_exportar_municipios = os.path.join(ruta_exportar, 'mun_iter')\n",
    "# Revisar si existe directorio de municipios sino\n",
    "if not os.path.isdir(ruta_exportar_municipios): os.mkdir(ruta_exportar_municipios)\n",
    "else: print('Directorio municipios ya existe.')\n",
    "# Exportar tablas csv y csvt de municipios\n",
    "for nombre, tabla in tablas_municipios.items():\n",
    "    exportar_csv_con_csvt(nombre, ruta_exportar_municipios, tabla)\n",
    "\n",
    "# Ruta para guardar tablas iter de localidades\n",
    "ruta_exportar_localidades = os.path.join(ruta_exportar, 'loc_iter')\n",
    "# Revisar si existe directorio de estados sino crearlo\n",
    "if not os.path.isdir(ruta_exportar_localidades): os.mkdir(ruta_exportar_localidades)\n",
    "else: print('Directorio localidades ya existe.')\n",
    "for nombre, tabla in tablas_localidad.items():\n",
    "    exportar_csv_con_csvt(nombre, ruta_exportar_localidades, tabla)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
